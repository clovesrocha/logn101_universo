{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "1. Defini√ß√£o do Problema/Objetivos (Observat√≥rio de Dados)\n",
        "\n",
        " A√ß√£o: Descreva em um par√°grafo o que √© o problema de Churn e qual o objetivo principal do projeto de Machine Learning (Ex: Minimizar Falsos Negativos √© crucial aqui, por que?).\n",
        "\n",
        "R:O problema de Churn ocorre quando clientes deixam de usar os produtos ou servi√ßos de uma empresa, o que representa perda de receita e aumento nos custos de aquisi√ß√£o de novos clientes.\n",
        "Em um projeto de Machine Learning voltado para prever o churn, o objetivo principal √© identificar, com anteced√™ncia, quais clientes t√™m maior probabilidade de cancelar, permitindo que a empresa tome a√ß√µes preventivas (como ofertas, suporte personalizado ou campanhas de reten√ß√£o).\n",
        "Minimizar falsos negativos √© crucial nesse contexto, pois um falso negativo significa classificar um cliente que realmente vai sair como se fosse permanecer ‚Äî e isso impede a empresa de agir a tempo para reter esse cliente, resultando em perda direta de faturamento.\n",
        "\n",
        "2. Coleta e Entendimento dos Dados (Bases alvos)\n",
        "\n",
        "import pandas as PD\n",
        "\n",
        "df = pd.read_csv('caminho_do_arquivo.csv')\n",
        "\n",
        "print(\"üîπ Primeiras 10 linhas:\")\n",
        "print(df.head(10))\n",
        "\n",
        "print(\"\\nüîπ Tipos de dados (dtypes):\")\n",
        "print(df.dtypes)\n",
        "\n",
        "print(\"\\nüîπ Quantidade de valores ausentes por coluna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "3. Tratamento/Prepara√ß√£o dos Dados (Pr√©-Processamento)\n",
        "\n",
        "a) R: import pandas as pd\n",
        "\n",
        "df = pd.read_csv('caminho_do_arquivo.csv')\n",
        "\n",
        "for coluna in df.columns:\n",
        "\n",
        "    if df[coluna].isnull().sum() > 0:\n",
        "        print(f\"üü° Coluna '{coluna}' possui {df[coluna].isnull().sum()} valores nulos.\")\n",
        "\n",
        "        if df[coluna].dtype in ['float64', 'int64']:\n",
        "            media = df[coluna].mean()\n",
        "            df[coluna].fillna(media, inplace=True)\n",
        "            print(f\"‚û°Ô∏è Valores nulos da coluna '{coluna}' foram substitu√≠dos pela m√©dia ({media:.2f}).\")\n",
        "\n",
        "        else:\n",
        "            moda = df[coluna].mode()[0]\n",
        "            df[coluna].fillna(moda, inplace=True)\n",
        "            print(f\"‚û°Ô∏è Valores nulos da coluna '{coluna}' foram substitu√≠dos pela moda ('{moda}').\")\n",
        "\n",
        "print(\"\\n‚úÖ Tratamento de nulos conclu√≠do!\")\n",
        "\n",
        "b) R: import pandas as pd\n",
        "\n",
        "df = pd.read_csv('caminho_do_arquivo.csv')\n",
        "\n",
        "colunas_categoricas = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "print(\"üîπ Colunas categ√≥ricas encontradas:\")\n",
        "print(colunas_categoricas)\n",
        "\n",
        "df_encoded = pd.get_dummies(df, columns=colunas_categoricas, drop_first=False)\n",
        "\n",
        "print(\"\\n‚úÖ One-Hot Encoding aplicado com sucesso!\")\n",
        "print(df_encoded.head())\n",
        "\n",
        "c) R: import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "df = pd.read_csv('caminho_do_arquivo.csv')\n",
        "\n",
        "colunas_numericas = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "print(\"üîπ Colunas num√©ricas identificadas:\")\n",
        "print(colunas_numericas)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_normalizado = df.copy()\n",
        "df_normalizado[colunas_numericas] = scaler.fit_transform(df[colunas_numericas])\n",
        "\n",
        "print(\"\\n‚úÖ Escalonamento aplicado com sucesso!\")\n",
        "print(df_normalizado.head())\n",
        "\n",
        "4. An√°lise Explorat√≥ria (Minera√ß√£o)\n",
        "\n",
        " R : import pandas as pd\n",
        "\n",
        "df = pd.read_csv('caminho_do_arquivo.csv')\n",
        "\n",
        "proporcao = df['Churn'].value_counts(normalize=True)\n",
        "\n",
        "print(\"üîπ Propor√ß√£o de classes (Churn vs N√£o-Churn):\")\n",
        "print((proporcao * 100).round(2).astype(str) + '%')\n",
        "\n",
        "5. Modelagem do Algoritmo (Minera√ß√£o)\n",
        "\n",
        "R: A√ß√£o\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "df = pd.read_csv('caminho_do_arquivo.csv')\n",
        "\n",
        "X = df.drop('Churn', axis=1)\n",
        "y = df['Churn']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "modelo = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "print(\"üîπ Acur√°cia:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nüîπ Relat√≥rio de Classifica√ß√£o:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\\nüîπ Matriz de Confus√£o:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "Foco em L√≥gica e Algoritmos:\n",
        "\n",
        "R: Para Regress√£o Log√≠stica = A Regress√£o Log√≠stica combina as vari√°veis em um valor z e a fun√ß√£o sigmoide transforma\n",
        "z em uma probabilidade entre 0 e 1, indicando a chance de um cliente dar churn.\n",
        "\n",
        "  Para √Årvores de Decis√£o = A √Årvore de Decis√£o escolhe a feature que melhor separa as classes,\n",
        "  usando Gini ou ganho de informa√ß√£o para medir qual divis√£o deixa os grupos mais puros.\n",
        "\n",
        "  6. An√°lise dos Resultados e Otimiza√ß√£o do Modelo (tuning)\n",
        "\n",
        "  R: from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matri\n",
        "\n",
        "acuracia = accuracy_score(y_test, y_pred)\n",
        "print(\"üîπ Acur√°cia:\", round(acuracia, 4)\n",
        "\n",
        "precisao = precision_score(y_test, y_pred)\n",
        "print(\"üîπ Precis√£o:\", round(precisao, 4))\n",
        "\n",
        "recall = recall_score(y_test, y_pred)\n",
        "print(\"üîπ Recall:\", round(recall, 4))\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"üîπ F1-Score:\", round(f1, 4))\n",
        "\n",
        "print(\"\\nüîπ Relat√≥rio de Classifica√ß√£o:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nüîπ Matriz de Confus√£o:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "      Foco em L√≥gica e Algoritmos:\n",
        "\n",
        "      a) Priorize Recall, porque o objetivo √© identificar o m√°ximo de clientes que podem cancelar, garantindo que a√ß√µes de reten√ß√£o atinjam quem realmente est√° em risco.\n",
        "\n",
        "      b)\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "modelo = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
        "\n",
        "scores = cross_val_score(modelo, X, y, cv=5, scoring='recall')  # aqui priorizamos Recall\n",
        "\n",
        "print(\"üîπ Recall m√©dio:\", round(np.mean(scores), 4))\n",
        "print(\"üîπ Desvio padr√£o:\", round(np.std(scores), 4))\n",
        "\n",
        "A Cross-Validation testa o modelo em diferentes subconjuntos do dataset, g\n",
        "arantindo que ele generalize melhor e que as m√©trica n√£o dependam de uma √∫nica divis√£o treino-teste.\n",
        "\n"
      ],
      "metadata": {
        "id": "FXjfBxKDKa-g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}