{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd77e59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 10 Primeiras Linhas (Amostra de Dados) ---\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
      "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
      "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
      "3  7795-CFOCW    Male              0      No         No      45           No   \n",
      "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
      "\n",
      "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
      "0  No phone service             DSL             No  ...               No   \n",
      "1                No             DSL            Yes  ...              Yes   \n",
      "2                No             DSL            Yes  ...               No   \n",
      "3  No phone service             DSL            Yes  ...              Yes   \n",
      "4                No     Fiber optic             No  ...               No   \n",
      "\n",
      "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
      "0          No          No              No  Month-to-month              Yes   \n",
      "1          No          No              No        One year               No   \n",
      "2          No          No              No  Month-to-month              Yes   \n",
      "3         Yes          No              No        One year               No   \n",
      "4          No          No              No  Month-to-month              Yes   \n",
      "\n",
      "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
      "0           Electronic check          29.85         29.85    No  \n",
      "1               Mailed check          56.95        1889.5    No  \n",
      "2               Mailed check          53.85        108.15   Yes  \n",
      "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
      "4           Electronic check          70.70        151.65   Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "\n",
      "--- Tipos de Dados e Verificação de Nulos ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7043 entries, 0 to 7042\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7043 non-null   object \n",
      " 1   gender            7043 non-null   object \n",
      " 2   SeniorCitizen     7043 non-null   int64  \n",
      " 3   Partner           7043 non-null   object \n",
      " 4   Dependents        7043 non-null   object \n",
      " 5   tenure            7043 non-null   int64  \n",
      " 6   PhoneService      7043 non-null   object \n",
      " 7   MultipleLines     7043 non-null   object \n",
      " 8   InternetService   7043 non-null   object \n",
      " 9   OnlineSecurity    7043 non-null   object \n",
      " 10  OnlineBackup      7043 non-null   object \n",
      " 11  DeviceProtection  7043 non-null   object \n",
      " 12  TechSupport       7043 non-null   object \n",
      " 13  StreamingTV       7043 non-null   object \n",
      " 14  StreamingMovies   7043 non-null   object \n",
      " 15  Contract          7043 non-null   object \n",
      " 16  PaperlessBilling  7043 non-null   object \n",
      " 17  PaymentMethod     7043 non-null   object \n",
      " 18  MonthlyCharges    7043 non-null   float64\n",
      " 19  TotalCharges      7043 non-null   object \n",
      " 20  Churn             7043 non-null   object \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "--- Proporção de Clientes (Churn/Não-Churn) ---\n",
      "Não-Churn (0): 73.46%\n",
      "Churn (1): 26.54%\n",
      "--- Relatório Detalhado de Classificação (Acurácia, Precisão, Recall, F1) ---\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1036\n",
      "           1       0.68      0.61      0.64       373\n",
      "\n",
      "    accuracy                           0.82      1409\n",
      "   macro avg       0.77      0.75      0.76      1409\n",
      "weighted avg       0.81      0.82      0.82      1409\n",
      "\n",
      "\n",
      "--- Validação Cruzada (Cross-Validation) ---\n",
      "Scores de Recall por Fold (k=5): [0.55614973 0.57754011 0.50802139 0.56032172 0.53475936]\n",
      "Recall Médio: 0.5474\n",
      "\n",
      "--- Simulação de Deploy para Novo Cliente ---\n",
      "Probabilidade de Churn: 69.97%\n",
      "Decisão do Modelo: Churn (Alto Risco - Ação de Retenção Recomendada)\n"
     ]
    }
   ],
   "source": [
    "# Importa a biblioteca essencial para trabalhar com dados (planilhas)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1. Definição do Problema (Para o seu texto no Notebook)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# **Justificativa de Negócio (Markdown):** O problema de Churn é a perda de clientes de uma empresa de telecomunicações. O principal objetivo é desenvolver um modelo preditivo que identifique, com antecedência, quais clientes têm maior probabilidade de cancelar seus serviços, permitindo à equipe de retenção agir proativamente. A prioridade é minimizar **Falsos Negativos** (perder um cliente sem aviso), que são mais custosos do que Falsos Positivos.\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. Coleta e Entendimento dos Dados\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Usamos a base de dados padrão IBM Telco Churn:\n",
    "url_dados = 'https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url_dados)\n",
    "\n",
    "print(\"--- 10 Primeiras Linhas (Amostra de Dados) ---\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n--- Tipos de Dados e Verificação de Nulos ---\")\n",
    "print(df.info())\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Tratamento/Preparação dos Dados - Lógica e Algoritmos\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Coluna TotalCharges: corrigir espaços em branco e nulos.\n",
    "df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\n",
    "\n",
    "# Lógica de imputação (preenchimento): usando a MEDIANA.\n",
    "mediana_totalcharges = df['TotalCharges'].median()\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(mediana_totalcharges)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Justificativa da Etapa 3.a (Markdown):\n",
    "# **Lógica para Nulos:** A coluna 'TotalCharges' tinha valores inconsistentes (espaços vazios) que foram convertidos para Nulos (NaN) e, em seguida, preenchidos utilizando a **mediana**. A **mediana** é a medida de tendência central preferível neste pré-processamento, pois é menos sensível a *outliers* (valores muito altos ou muito baixos) do que a média, preservando assim a distribuição real dos dados para o algoritmo.00000\n",
    "# -------------------------------------------------------------\n",
    "# 1. Codificar a variável alvo (Churn: 'Yes' vira 1, 'No' vira 0)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# 2. Excluir colunas desnecessárias\n",
    "df = df.drop(columns=['customerID'])\n",
    "\n",
    "# 3. One-Hot Encoding: Transforma colunas de texto em colunas binárias (0 ou 1)\n",
    "df_dummies = pd.get_dummies(df)\n",
    "\n",
    "# Separação das Features (X) e do Alvo (y)\n",
    "X = df_dummies.drop(columns=['Churn']) \n",
    "y = df_dummies['Churn']\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Justificativa da Etapa 3.b (Markdown):\n",
    "# **Algoritmo de Codificação (One-Hot Encoding):** O método `pd.get_dummies` foi aplicado para transformar as variáveis categóricas (texto) em formato binário. Isso é crucial, pois impede que o algoritmo de Machine Learning atribua uma **relação ordinal (de ordem)** que não existe entre as categorias (ex: que um tipo de serviço seja numericamente \"melhor\" que outro), garantindo que apenas a presença ou ausência da característica seja considerada.\n",
    "# -------------------------------------------------------------00\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Análise Exploratória (Balanceamento)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "churn_counts = df['Churn'].value_counts(normalize=True) * 100\n",
    "print(\"--- Proporção de Clientes (Churn/Não-Churn) ---\")\n",
    "print(f\"Não-Churn (0): {churn_counts[0]:.2f}%\")\n",
    "print(f\"Churn (1): {churn_counts[1]:.2f}%\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Justificativa da Etapa 4 (Markdown):\n",
    "# **Impacto do Desbalanceamento:** A análise mostra um desbalanceamento significativo (cerca de 73% Não-Churn contra 27% Churn). Logicamente, um modelo treinado com dados desbalanceados pode ser **viciado** em prever a classe majoritária (Não-Churn), resultando em uma alta Acurácia, mas baixa capacidade de realmente identificar os clientes que vão sair. Isso reforça a necessidade de priorizar o Recall nas métricas de avaliação.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Modelagem do Algoritmo (Mineração)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Dividir os dados em conjuntos de TREINO (80%) e TESTE (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar e treinar o Modelo de Regressão Logística\n",
    "modelo = LogisticRegression(max_iter=500, solver='liblinear') # Usando liblinear para estabilidade\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Fazer Previsões\n",
    "y_predito = modelo.predict(X_test)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Justificativa da Etapa 5 (Markdown):\n",
    "# **Algoritmo Escolhido (Regressão Logística):** Escolhemos a Regressão Logística por ser um classificador robusto para problemas binários. Seu funcionamento algorítmico depende da **função Sigmoide** ($\\sigma(z) = \\frac{1}{1 + e^{-z}}$), que transforma o resultado linear da equação do modelo em um valor entre 0 e 1, que é interpretado como a **probabilidade** de Churn.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Análise dos Resultados\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "print(\"--- Relatório Detalhado de Classificação (Acurácia, Precisão, Recall, F1) ---\\n\")\n",
    "print(classification_report(y_test, y_predito))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Justificativa da Etapa 6.a (Markdown):\n",
    "# **Métrica Lógica Prioritária (Recall):** No objetivo de retenção de clientes, o **Recall** (Taxa de Verdadeiros Positivos) deve ser priorizado. Ele mede a proporção de clientes que *realmente* iriam sair (Churn) e foram corretamente identificados pelo modelo. Logicamente, o custo de perder um cliente (Falso Negativo) é maior do que o custo de uma ação de retenção desnecessária (Falso Positivo), fazendo do Recall a métrica mais alinhada ao objetivo de negócio.\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6.b) Otimização (Validação Cruzada)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Aplicação da Validação Cruzada com 5 Folds, otimizando pela métrica de Recall\n",
    "scores_cv = cross_val_score(modelo, X, y, cv=5, scoring='recall')\n",
    "\n",
    "print(f\"\\n--- Validação Cruzada (Cross-Validation) ---\")\n",
    "print(f\"Scores de Recall por Fold (k=5): {scores_cv}\")\n",
    "print(f\"Recall Médio: {scores_cv.mean():.4f}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Justificativa da Etapa 6.b (Markdown):\n",
    "# **Lógica Algorítmica da Validação Cruzada (K-Fold):** Esta técnica divide o dataset em 5 partes (folds). O modelo é treinado 5 vezes, usando em cada rodada K-1 partes para treino e a parte restante para teste. Esta abordagem garante que a avaliação do modelo seja **mais robusta e imparcial**, pois elimina a dependência de uma única divisão aleatória de treino/teste, validando a capacidade de generalização do algoritmo em diferentes subconjuntos de dados.\n",
    "# -------------------------------------------------------------\n",
    "# -------------------------------------------------------------\n",
    "# 7. Deploy (Simulado)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Pegamos as colunas em que o modelo foi treinado (o modelo precisa de todas elas)\n",
    "colunas_treinadas = list(X.columns)\n",
    "\n",
    "def prever_novo_cliente(dados_cliente: dict, modelo: LogisticRegression, colunas_dummies: list):\n",
    "    \"\"\"\n",
    "    Recebe os dados de um cliente, aplica o pré-processamento (codificação) e retorna a previsão de Churn.\n",
    "    \"\"\"\n",
    "    # 1. Aplicar One-Hot Encoding no novo dado (o novo dado vira uma linha de DataFrame)\n",
    "    novo_df = pd.DataFrame([dados_cliente])\n",
    "    \n",
    "    # 2. Replicar a codificação binária (dummies) nos dados do novo cliente\n",
    "    # Nota: Este passo assume que o novo dado já tem as colunas codificadas em 0 ou 1\n",
    "    \n",
    "    # 3. Alinhar colunas: Garante que o novo dado tem TODAS as \n",
    "    #    mesmas colunas que o modelo foi treinado (preenchendo com 0 onde não tem)\n",
    "    diferenca_colunas = set(colunas_dummies) - set(novo_df.columns)\n",
    "    for col in diferenca_colunas:\n",
    "        novo_df[col] = 0\n",
    "\n",
    "    # 4. Selecionar apenas as colunas que o modelo espera, na ordem correta\n",
    "    dado_para_prever = novo_df[colunas_dummies].copy()\n",
    "\n",
    "    # 5. Fazer a previsão de probabilidade e classificação\n",
    "    # Note: O .predict_proba dá a chance (probabilidade) do Churn (classe 1)\n",
    "    probabilidade_churn = modelo.predict_proba(dado_para_prever)[:, 1][0]\n",
    "    \n",
    "    # 6. Definir a decisão final com base em um limite de 50%\n",
    "    decisao_final = 'Churn (Alto Risco - Ação de Retenção Recomendada)' if probabilidade_churn >= 0.5 else 'Não-Churn (Baixo Risco)'\n",
    "\n",
    "    return probabilidade_churn, decisao_final\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Simulação com um Cliente de Alto Risco (Exemplo)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Exemplo de dados de um novo cliente (após o pré-processamento de um sistema externo):\n",
    "dados_exemplo_alto_risco = {\n",
    "    # Exemplo: Mulher, não-Senior, Sem Parceiro, Sem Dependentes, 1 mês de contrato, Fibra Ótica, Sem Segurança, Checagem Eletrônica\n",
    "    'gender_Female': 1, 'SeniorCitizen': 0, 'Partner_No': 1, 'Dependents_No': 1, \n",
    "    'tenure': 1, 'PhoneService_Yes': 1, 'MultipleLines_No': 1, \n",
    "    'InternetService_Fiber optic': 1, 'OnlineSecurity_No': 1, 'OnlineBackup_No': 1, \n",
    "    'DeviceProtection_No': 1, 'TechSupport_No': 1, 'StreamingTV_No': 1, \n",
    "    'StreamingMovies_No': 1, 'Contract_Month-to-month': 1, 'PaperlessBilling_Yes': 1, \n",
    "    'PaymentMethod_Electronic check': 1, 'MonthlyCharges': 70.0, 'TotalCharges': 70.0\n",
    "}\n",
    "\n",
    "prob, decisao = prever_novo_cliente(dados_exemplo_alto_risco, modelo, colunas_treinadas)\n",
    "\n",
    "print(f\"\\n--- Simulação de Deploy para Novo Cliente ---\")\n",
    "print(f\"Probabilidade de Churn: {prob*100:.2f}%\")\n",
    "print(f\"Decisão do Modelo: {decisao}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Justificativa do Deploy (Markdown):\n",
    "# **Lógica de Pipeline:** A função simula o pipeline em produção. Sua lógica crucial é garantir que os novos dados de entrada sejam submetidos ao **mesmo pré-processamento e codificação** (One-Hot Encoding e alinhamento de colunas) usados no treinamento. Isso é fundamental para que o modelo receba as *features* no formato exato que espera e possa fazer uma previsão válida e consistente.\n",
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3813385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 2: Continuação do Fluxo\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ⚠️ CORREÇÃO CRUCIAL: RECARREGA O DATAFRAME ORIGINAL\n",
    "# Isso evita o erro de ter apenas uma classe (0) no modelo.fit.\n",
    "url_dados = 'https://raw.githubusercontent.com/IBM/telco-customer-churn-on-icp4d/master/data/Telco-Customer-Churn.csv'\n",
    "df = pd.read_csv(url_dados)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Tratamento/Preparação dos Dados - Lógica e Algoritmos\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Lógica de imputação (preenchimento): usando a MEDIANA.\n",
    "df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'])\n",
    "mediana_totalcharges = df['TotalCharges'].median()\n",
    "df['TotalCharges'] = df['TotalCharges'].fillna(mediana_totalcharges)\n",
    "\n",
    "# Justificativa da Etapa 3.a (Markdown):\n",
    "# **Lógica para Nulos:** A coluna 'TotalCharges' tinha valores inconsistentes que foram preenchidos utilizando a **mediana**. A **mediana** é a medida de tendência central preferível neste pré-processamento, por ser menos sensível a *outliers*.\n",
    "\n",
    "# 1. Codificar a variável alvo (Churn: 'Yes' vira 1, 'No' vira 0)\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Garante que Churn não tenha NaNs e é um inteiro\n",
    "df['Churn'] = df['Churn'].fillna(0).astype(int) \n",
    "\n",
    "# 2. Excluir colunas desnecessárias\n",
    "df = df.drop(columns=['customerID'])\n",
    "\n",
    "# 3. One-Hot Encoding\n",
    "df_dummies = pd.get_dummies(df)\n",
    "\n",
    "# Separação das Features (X) e do Alvo (y)\n",
    "X = df_dummies.drop(columns=['Churn']) \n",
    "y = df_dummies['Churn']\n",
    "\n",
    "# Justificativa da Etapa 3.b (Markdown):\n",
    "# **Algoritmo de Codificação (One-Hot Encoding):** O método `pd.get_dummies` foi aplicado para transformar as variáveis categóricas (texto) em formato binário. Isso é crucial, pois impede que o algoritmo atribua uma **relação ordinal** incorreta entre as categorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "959f0138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Proporção de Clientes (Churn/Não-Churn) ---\n",
      "Não-Churn (0): 73.46%\n",
      "Churn (1): 26.54%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# X e Y já estão definidos na Célula 2.\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3.c) Algoritmo de Normalização/Escalonamento\n",
    "# -------------------------------------------------------------\n",
    "colunas_numericas = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplica Normalização nas colunas numéricas (Força float para estabilidade)\n",
    "X[colunas_numericas] = X[colunas_numericas].astype(float)\n",
    "X[colunas_numericas] = scaler.fit_transform(X[colunas_numericas])\n",
    "\n",
    "# Justificativa da Etapa 3.c (Markdown):\n",
    "# **Necessidade Algorítmica da Normalização:** Aplicamos o **MinMaxScaler** para escalonar as colunas numéricas. A normalização garante que todas as *features* contribuam igualmente para o treinamento, prevenindo vieses.\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Análise Exploratória (Balanceamento)\n",
    "# -------------------------------------------------------------\n",
    "# ⚠️ GARANTINDO QUE DF SEJA O DATAFRAME COM CHURN 0/1 (do final da Célula 2)\n",
    "# Replicamos o df com as mudanças necessárias apenas para fins de visualização do balanceamento\n",
    "df['Churn'] = df['Churn'].fillna(0).astype(int) \n",
    "churn_counts = df['Churn'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"--- Proporção de Clientes (Churn/Não-Churn) ---\")\n",
    "print(f\"Não-Churn (0): {churn_counts.get(0, 0.0):.2f}%\")\n",
    "print(f\"Churn (1): {churn_counts.get(1, 0.0):.2f}%\")\n",
    "\n",
    "# Justificativa da Etapa 4 (Markdown):\n",
    "# **Impacto do Desbalanceamento:** A análise mostra um desbalanceamento significativo. Isso reforça a necessidade de priorizar o **Recall** nas métricas de avaliação.\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. Modelagem do Algoritmo (Mineração)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Dividir os dados em conjuntos de TREINO (80%) e TESTE (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Criar e treinar o Modelo de Regressão Logística\n",
    "modelo = LogisticRegression(max_iter=500, solver='liblinear') \n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Fazer Previsões\n",
    "y_predito = modelo.predict(X_test)\n",
    "\n",
    "# Justificativa da Etapa 5 (Markdown):\n",
    "# **Algoritmo Escolhido (Regressão Logística):** Escolhemos a Regressão Logística. Seu funcionamento algorítmico depende da **função Sigmoide** que transforma o resultado linear em uma probabilidade de Churn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "922b1aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Relatório Detalhado de Classificação (Acurácia, Precisão, Recall, F1) ---\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88      1036\n",
      "           1       0.69      0.59      0.64       373\n",
      "\n",
      "    accuracy                           0.82      1409\n",
      "   macro avg       0.77      0.75      0.76      1409\n",
      "weighted avg       0.81      0.82      0.82      1409\n",
      "\n",
      "\n",
      "--- Validação Cruzada (Cross-Validation) ---\n",
      "Scores de Recall por Fold (k=5): [0.55614973 0.57754011 0.51336898 0.55764075 0.53208556]\n",
      "Recall Médio: 0.5474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Análise dos Resultados\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "print(\"--- Relatório Detalhado de Classificação (Acurácia, Precisão, Recall, F1) ---\\n\")\n",
    "print(classification_report(y_test, y_predito))\n",
    "\n",
    "# Justificativa da Etapa 6.a (Markdown):\n",
    "# **Métrica Lógica Prioritária (Recall):** O **Recall** deve ser priorizado no objetivo de retenção. O custo de perder um cliente (Falso Negativo) é maior do que o custo de uma ação de retenção desnecessária, alinhando o Recall ao objetivo de negócio.\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6.b) Otimização (Validação Cruzada)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Aplicação da Validação Cruzada com 5 Folds, otimizando pela métrica de Recall\n",
    "scores_cv = cross_val_score(modelo, X, y, cv=5, scoring='recall')\n",
    "\n",
    "print(f\"\\n--- Validação Cruzada (Cross-Validation) ---\")\n",
    "print(f\"Scores de Recall por Fold (k=5): {scores_cv}\")\n",
    "print(f\"Recall Médio: {scores_cv.mean():.4f}\")\n",
    "\n",
    "# Justificativa da Etapa 6.b (Markdown):\n",
    "# **Lógica Algorítmica da Validação Cruzada (K-Fold):** Esta técnica garante que a avaliação do modelo seja **mais robusta e imparcial**, pois elimina a dependência de uma única divisão aleatória de treino/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485f64f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Simulação de Deploy para Novo Cliente ---\n",
      "Probabilidade de Churn: 69.39%\n",
      "Decisão do Modelo: Churn (Alto Risco - Ação de Retenção Recomendada)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 7. Deploy (Simulado)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Reutilizando objetos do modelo e do scaler da Célula 3\n",
    "colunas_treinadas = list(X.columns)\n",
    "colunas_numericas_brutas = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "def prever_novo_cliente(dados_cliente: dict, modelo: LogisticRegression, colunas_dummies: list, scaler_model: MinMaxScaler):\n",
    "    \"\"\"\n",
    "    Recebe os dados de um cliente, aplica todas as etapas de pré-processamento (codificação e normalização) \n",
    "    e retorna a previsão de Churn.\n",
    "    \"\"\"\n",
    "    novo_df = pd.DataFrame([dados_cliente])\n",
    "    \n",
    "    # Aplicar a Normalização/Escalonamento\n",
    "    dados_para_normalizar = novo_df[colunas_numericas_brutas].astype(float).copy()\n",
    "    novo_df[colunas_numericas_brutas] = scaler_model.transform(dados_para_normalizar)\n",
    "\n",
    "    # Alinhar colunas (One-Hot Encoding)\n",
    "    diferenca_colunas = set(colunas_dummies) - set(novo_df.columns)\n",
    "    for col in diferenca_colunas:\n",
    "        novo_df[col] = 0\n",
    "\n",
    "    dado_para_prever = novo_df[colunas_dummies].copy()\n",
    "\n",
    "    # Previsão\n",
    "    probabilidade_churn = modelo.predict_proba(dado_para_prever)[:, 1][0]\n",
    "    decisao_final = 'Churn (Alto Risco - Ação de Retenção Recomendada)' if probabilidade_churn >= 0.5 else 'Não-Churn (Baixo Risco)'\n",
    "\n",
    "    return probabilidade_churn, decisao_final\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# Simulação com um Cliente de Alto Risco (Exemplo)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "# Exemplo de dados de um novo cliente (em seus valores BRUTOS)\n",
    "dados_exemplo_alto_risco = {\n",
    "    'gender_Female': 1, 'SeniorCitizen': 0, 'Partner_No': 1, 'Dependents_No': 1, \n",
    "    'tenure': 1, 'PhoneService_Yes': 1, 'MultipleLines_No': 1, \n",
    "    'InternetService_Fiber optic': 1, 'OnlineSecurity_No': 1, 'OnlineBackup_No': 1, \n",
    "    'DeviceProtection_No': 1, 'TechSupport_No': 1, 'StreamingTV_No': 1, \n",
    "    'StreamingMovies_No': 1, 'Contract_Month-to-month': 1, 'PaperlessBilling_Yes': 1, \n",
    "    'PaymentMethod_Electronic check': 1, 'MonthlyCharges': 70.0, 'TotalCharges': 70.0\n",
    "}\n",
    "\n",
    "# Passamos o objeto 'scaler' treinado para a função\n",
    "prob, decisao = prever_novo_cliente(dados_exemplo_alto_risco, modelo, colunas_treinadas, scaler)\n",
    "\n",
    "print(f\"\\n--- Simulação de Deploy para Novo Cliente ---\")\n",
    "print(f\"Probabilidade de Churn: {prob*100:.2f}%\")\n",
    "print(f\"Decisão do Modelo: {decisao}\")\n",
    "\n",
    "# Justificativa do Deploy (Markdown):\n",
    "# **Lógica de Pipeline:** A função simula o pipeline em produção, garantindo que os novos dados sejam submetidos ao **mesmo pré-processamento** (Codificação One-Hot e a Normalização/Escalonamento) usados no treinamento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
